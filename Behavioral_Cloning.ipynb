{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 1.3.0\n",
      "Keras version 2.0.8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import sklearn.utils\n",
    "import sklearn.model_selection\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "print('Tensorflow version {0}'.format(tf.__version__))\n",
    "print('Keras version {0}'.format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_brightness(img, lower_bound=0, upper_bound=255):\n",
    "    '''\n",
    "    Uniformly changes the brightness of an image randomly without overflowing.\n",
    "    Change in brightness limited by original brightness of image\n",
    "    '''\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    img[:,:,2] = img[:,:,2]/2 + np.random.randint(lower_bound, upper_bound)/2\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def bin_angles(y, n_bins = 20):\n",
    "#     '''Computes a bin number for each steering angle in order to balance classes'''\n",
    "#     return np.floor((y - np.min(y))*n_bins/(np.max(y) - np.min(y)))\n",
    "\n",
    "def bin_weights(y, n_bins=10):\n",
    "    '''Balances numbered classes and returns array of weights to apply to each class'''\n",
    "    y_bins = np.floor((y - np.min(y))*n_bins/(np.max(y) - np.min(y)))\n",
    "    class_weight = sklearn.utils.class_weight.compute_class_weight('balanced', \n",
    "                                                                   np.unique(y_bins), \n",
    "                                                                   y_bins)\n",
    "    class_dict = dict(zip(np.unique(y_bins), class_weight))\n",
    "    return np.vectorize(class_dict.get)(y_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File I/O\n",
    "Want to read in a directory of jpg files and write out hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalanced Classes\n",
    "We would like to have an equal distribution of steering angles to reduce the bias for zero driving angle. We will apply sample weights to balance the effect of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate CSV into numpy array of strings and numpy array of floats\n",
    "file_paths = np.genfromtxt('./driving_data/driving_log.csv', dtype=np.str, usecols=(0,1,2), delimiter=',')\n",
    "homogenous_samples = np.genfromtxt('./driving_data/driving_log.csv', delimiter=',', usecols=(3,4,5,6))\n",
    "# Compute sample weights\n",
    "steering_angles = homogenous_samples[:,0]\n",
    "homogenous_samples = np.hstack((homogenous_samples, \n",
    "                        np.expand_dims(bin_weights(steering_angles), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(steering_angles, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save files to directory so that we can read them with `flow_from_directory`. Shoving them into an array causes memory errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Conv2D\n",
    "from keras.layers import MaxPooling2D, Cropping2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((20,8), (0,0)), input_shape=(64,128,3)))\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5))\n",
    "model.add(Conv2D(24, (5,5), activation='elu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(36, (5,5), activation='elu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(48, (5,5), activation='elu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, (3,3), activation='elu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='elu'))\n",
    "model.add(Dense(50, activation='elu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.0001))\n",
    "history_object = model.fit(X, y, validation_split=0.2, \n",
    "          sample_weight=y_weights, shuffle=True, verbose=2)\n",
    "model.save('model{0}.h5'.format(np.datetime_as_string(np.datetime64('now'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L-R Camera compensation\n",
    "\n",
    "A correction factor of 0.1 is added to the left camera and subtracted from the right camera to compensate for the lateral position of the camera relative to the center. The value of the correction factor should be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(file_paths, samples, batch_size, lr_shift):\n",
    "    num_samples = len(samples)\n",
    "    if len(samples) != len(file_paths):\n",
    "        print('TODO: Error Message, incompatible arrays {0} {1}'.format(len(samples), len(file_paths)))\n",
    "    while True:\n",
    "        file_paths, samples = sklearn.utils.shuffle(file_paths, samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_files = file_paths[offset:offset + batch_size]\n",
    "            batch_samples = samples[offset:offset + batch_size]\n",
    "            \n",
    "            images = []\n",
    "            measurements = []\n",
    "            weights = []\n",
    "            for batch_file in batch_files:\n",
    "                #Read images from file\n",
    "                center_file  = batch_file[0]\n",
    "                left_file    = batch_file[1]\n",
    "                right_file   = batch_file[2]\n",
    "                center_image = mpimg.imread(center_file)\n",
    "                left_image   = mpimg.imread(left_file)\n",
    "                right_image  = mpimg.imread(right_file)\n",
    "                #Change brightness of images\n",
    "                center_image = change_brightness(center_image)\n",
    "                left_image = change_brightness(left_image)\n",
    "                right_image = change_brightness(right_image)\n",
    "                images.append(center_image)\n",
    "                images.append(left_image)\n",
    "                images.append(right_image)\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                steer_angle  = batch_sample[0]\n",
    "                sample_weight = batch_sample[4]\n",
    "                \n",
    "                #Steering angle offsets\n",
    "                measurements.append(steer_angle)\n",
    "                measurements.append(steer_angle+lr_shift)\n",
    "                measurements.append(steer_angle-lr_shift)\n",
    "                weights += [sample_weight]*3\n",
    "                \n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(measurements)\n",
    "            y_weights = np.array(weights)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train, y_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHIFT = 0.1\n",
    "train_files, val_files, train_samples, val_samples = \\\n",
    "    sklearn.model_selection.train_test_split(file_paths, homogenous_samples, test_size=0.2)\n",
    "train_generator = generator(train_files, train_samples, batch_size=BATCH_SIZE, lr_shift=SHIFT)\n",
    "validation_generator = generator(val_files, val_samples, batch_size=BATCH_SIZE, lr_shift=SHIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "207s - loss: 0.1758 - val_loss: 0.1286\n",
      "Epoch 2/10\n",
      "203s - loss: 0.1046 - val_loss: 0.0887\n",
      "Epoch 3/10\n",
      "203s - loss: 0.0868 - val_loss: 0.0825\n",
      "Epoch 4/10\n",
      "206s - loss: 0.0756 - val_loss: 0.0792\n",
      "Epoch 5/10\n",
      "201s - loss: 0.0669 - val_loss: 0.0720\n",
      "Epoch 6/10\n",
      "202s - loss: 0.0580 - val_loss: 0.0704\n",
      "Epoch 7/10\n",
      "208s - loss: 0.0534 - val_loss: 0.0710\n",
      "Epoch 8/10\n",
      "208s - loss: 0.0483 - val_loss: 0.0701\n",
      "Epoch 9/10\n",
      "201s - loss: 0.0440 - val_loss: 0.0729\n",
      "Epoch 10/10\n",
      "210s - loss: 0.0408 - val_loss: 0.0661\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Conv2D\n",
    "from keras.layers import MaxPooling2D, Cropping2D, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160,320,3)))\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5))\n",
    "model.add(Conv2D(36, (5,5), activation='elu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(48, (3,3), activation='elu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, (3,3), activation='elu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='elu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.0001))\n",
    "history_object = model.fit_generator(train_generator, \n",
    "                                     steps_per_epoch=len(train_samples)/BATCH_SIZE,\n",
    "                                     validation_data=validation_generator, \n",
    "                                     validation_steps=len(val_samples)/BATCH_SIZE,\n",
    "                                     epochs=10, \n",
    "                                     verbose=2)\n",
    "model.save('model{0}.h5'.format(np.datetime_as_string(np.datetime64('now'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_10 (Cropping2D)   (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_10 (Lambda)           (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 90, 320, 36)       2736      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 45, 160, 36)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 45, 160, 48)       15600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 22, 80, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 22, 80, 64)        27712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 11, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 28160)             0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 512)               14418432  \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 14,534,305\n",
      "Trainable params: 14,534,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# center = mpimg.imread(log['CenterImg'][0])\n",
    "# left = mpimg.imread(log['LeftImg'][0])\n",
    "# right = mpimg.imread(log['RightImg'][0])\n",
    "fig = plt.figure(figsize=(12,3))\n",
    "plt.suptitle('Car Images')\n",
    "axl = plt.subplot(1,3,1)\n",
    "plt.imshow(left)\n",
    "axc = plt.subplot(1,3,2)\n",
    "plt.imshow(center)\n",
    "axr = plt.subplot(1,3,3)\n",
    "plt.imshow(right)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
