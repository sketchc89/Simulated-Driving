{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import sklearn.utils\n",
    "import sklearn.model_selection\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "print('Tensorflow version {0}'.format(tf.__version__))\n",
    "print('Keras version {0}'.format(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File I/O\n",
    "Want to read in a directory of jpg files and write out hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('./driving_data/driving_log.csv', names=['CenterImg', 'LeftImg', 'RightImg', \n",
    "                                                           'SteeringAngle', 'Throttle', 'Break', 'Speed'])\n",
    "log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L-R Camera compensation\n",
    "\n",
    "A correction factor of 0.1 degrees is added to the left camera and subtracted from the right camera to compensate for the lateral position of the camera relative to the center. The value of the correction factor should be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_brightness(img, lower_bound=0, upper_bound=255):\n",
    "    '''\n",
    "    Uniformly changes the brightness of an image randomly without overflowing.\n",
    "    Change in brightness limited by original brightness of image\n",
    "    '''\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    img[:,:,2] = img[:,:,2]/2 + np.random.randint(lower_bound, upper_bound)/2\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "measurements = []\n",
    "image_path = []\n",
    "offset = 0.15\n",
    "new_scale = (256, 128)\n",
    "\n",
    "for i in range(log.shape[0]):\n",
    "    #Original    \n",
    "    center = mpimg.imread(log['CenterImg'][i])\n",
    "    left = mpimg.imread(log['LeftImg'][i])\n",
    "    right = mpimg.imread(log['RightImg'][i])\n",
    "    \n",
    "    #Scale down images\n",
    "#     center = cv2.resize(center, new_scale, interpolation=cv2.INTER_AREA)\n",
    "#     left = cv2.resize(left, new_scale, interpolation=cv2.INTER_AREA)\n",
    "#     right = cv2.resize(right, new_scale, interpolation=cv2.INTER_AREA)\n",
    "    #Change brightness of images\n",
    "    center = change_brightness(center)\n",
    "    left = change_brightness(left)\n",
    "    right = change_brightness(right)\n",
    "    \n",
    "    images.append(center)\n",
    "    images.append(left)\n",
    "    images.append(right)\n",
    "    measurements.append(log['SteeringAngle'][i])\n",
    "    measurements.append(log['SteeringAngle'][i]+offset)\n",
    "    measurements.append(log['SteeringAngle'][i]-offset)\n",
    "#     image_path.append(log['CenterImg'][i])\n",
    "#     image_path.append(log['LeftImg'][i])\n",
    "#     image_path.append(log['RightImg'][i])\n",
    "\n",
    "    #Flipped\n",
    "    images.append(np.fliplr(center))\n",
    "    images.append(np.fliplr(left))\n",
    "    images.append(np.fliplr(right))\n",
    "    measurements.append(-log['SteeringAngle'][i])\n",
    "    measurements.append(-log['SteeringAngle'][i]-offset)\n",
    "    measurements.append(-log['SteeringAngle'][i]+offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalanced Classes\n",
    "We would like to have an equal distribution of steering angles to reduce the bias for zero driving angle. We will apply sample weights to balance the effect of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def bin_angles(y, n_bins = 20):\n",
    "#     '''Computes a bin number for each steering angle in order to balance classes'''\n",
    "#     return np.floor((y - np.min(y))*n_bins/(np.max(y) - np.min(y)))\n",
    "\n",
    "def bin_weights(y, n_bins=10):\n",
    "    '''Balances numbered classes and returns array of weights to apply to each class'''\n",
    "    y_bins = np.floor((y - np.min(y))*n_bins/(np.max(y) - np.min(y)))\n",
    "    class_weight = sklearn.utils.class_weight.compute_class_weight('balanced', \n",
    "                                                                   np.unique(y_bins), \n",
    "                                                                   y_bins)\n",
    "    class_dict = dict(zip(np.unique(y_bins), class_weight))\n",
    "    return np.vectorize(class_dict.get)(y_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "\n",
    "# X_train, X_test, y_train, y_test, y_train_weights, y_test_weights = sklearn.model_selection.train_test_split(\n",
    "#                                                                             X, y, y_weights, \n",
    "#                                                                             test_size=0.2, random_state=1)\n",
    "# X_train, X_val, y_train, y_val, y_train_weights, y_val_weights = sklearn.model_selection.train_test_split(\n",
    "#                                                                     X_train, y_train, y_train_weights, \n",
    "#                                                                     test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(measurements)\n",
    "y_weights = bin_weights(y)\n",
    "\n",
    "#Check whether contains nan\n",
    "print('y contains nan: {}'.format(np.isnan(np.min(y))))\n",
    "print('y_weights contains nan: {}'.format(np.isnan(np.min(y_weights))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save files to directory so that we can read them with `flow_from_directory`. Shoving them into an array causes memory errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Generator\n",
    "* Images are flipped in order to reduce bias towards driving on slightly towards one side of the road.\n",
    "* ZCA Whitening is applied\n",
    "* Image generator probably won't work without classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# img_width=320\n",
    "# img_height=160\n",
    "# batch_size=32\n",
    "# datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "#             featurewise_center=True,\n",
    "# #             featurewise_std_normalization=False,\n",
    "#             zca_whitening=True,\n",
    "#             horizontal_flip=True)\n",
    "# datagen.flow_from_directory('./driving_data/train/',\n",
    "#                             target_size=(img_width, img_height),\n",
    "#                             batch_size=batch_size,\n",
    "#                             class_mode=None, \n",
    "#                             classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Conv2D\n",
    "from keras.layers import MaxPooling2D, Cropping2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((20,8), (0,0)), input_shape=(64,128,3)))\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5))\n",
    "model.add(Conv2D(24, (5,5), activation='elu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(36, (5,5), activation='elu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(48, (5,5), activation='elu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, (3,3), activation='elu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='elu'))\n",
    "model.add(Dense(50, activation='elu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.0001))\n",
    "history_object = model.fit(X, y, validation_split=0.2, \n",
    "          sample_weight=y_weights, shuffle=True, verbose=2)\n",
    "model.save('model{0}.h5'.format(np.datetime_as_string(np.datetime64('now'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Conv2D\n",
    "from keras.layers import MaxPooling2D, Cropping2D, Dropout\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160,320,3)))\n",
    "model2.add(Lambda(lambda x: x/255.0 - 0.5))\n",
    "model2.add(Conv2D(36, (5,5), activation='elu', padding='same'))\n",
    "model2.add(MaxPooling2D())\n",
    "model2.add(Conv2D(48, (3,3), activation='elu', padding='same'))\n",
    "model2.add(MaxPooling2D())\n",
    "model2.add(Conv2D(64, (3,3), activation='elu', padding='same'))\n",
    "model2.add(MaxPooling2D())\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(512, activation='elu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(128, activation='elu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(32, activation='elu'))\n",
    "model2.add(Dense(1))\n",
    "model2.compile(loss='mse', optimizer=Adam(lr=0.0001))\n",
    "history_object2 = model2.fit(X, y, validation_split=0.2, \n",
    "                             sample_weight=y_weights, shuffle=True, \n",
    "                             epochs=25, verbose=2)\n",
    "model2.save('model{0}.h5'.format(np.datetime_as_string(np.datetime64('now'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# center = mpimg.imread(log['CenterImg'][0])\n",
    "# left = mpimg.imread(log['LeftImg'][0])\n",
    "# right = mpimg.imread(log['RightImg'][0])\n",
    "fig = plt.figure(figsize=(12,3))\n",
    "plt.suptitle('Car Images')\n",
    "axl = plt.subplot(1,3,1)\n",
    "plt.imshow(left)\n",
    "axc = plt.subplot(1,3,2)\n",
    "plt.imshow(center)\n",
    "axr = plt.subplot(1,3,3)\n",
    "plt.imshow(right)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
